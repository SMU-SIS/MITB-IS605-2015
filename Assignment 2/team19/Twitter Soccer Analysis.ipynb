{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Twitter Soccer Analysis\n",
    "============\n",
    "*Insert description here*\n",
    "\n",
    "Data Overview\n",
    "--------------\n",
    "    Technical Data:\n",
    "    Instance   : Amazon EC2 (Ubuntu, m4.large)  \n",
    "    Database   : Amazon RDS (MySQL, t2.large)\n",
    "    Python     : 2.7 (Not working in python 3)\n",
    "\n",
    "    About the Data:\n",
    "    Souce      : Twitter Streaming API\n",
    "    Type       : JSON\n",
    "    Num. Rows  : 127,607  \n",
    "    Size       : approx. 1.6 GigaByte\n",
    "\n",
    "Preparation\n",
    "-----------\n",
    "In order to get data from database, we need to install MySQLdb first. MySQLdb is one of python library that provide driver or direct connection to MySQL database. As a result, all what we need is import MySQLdb into our machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Super User**  \n",
    "We need to have access to sudo command, so we can run installation command smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installing Anaconda**  \n",
    "We need to install Anaconda just in case if compatibility issue happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda2-2.4.0-Linux-x86_64.sh\n",
    "!bash Anaconda2-2.4.0-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process above is to download data from Anaconda website and to install Anaconda after downloading the data.\n",
    "\n",
    "**Installing MySQLdb**  \n",
    "Before going deeper to access database, we need to install MySQLdb first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pip --upgrade\n",
    "!apt-get build-dep python-mysqldb\n",
    "!pip install MySQL-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other Works**  \n",
    "We also did some of dirty works called **`Data Preparation`** such as:\n",
    "    * Getting and storing Twitter streaming data\n",
    "    * Extracting and counting, words and location based on timezone\n",
    "    * Cleaning words and location data\n",
    "If you are interested in \"How to we did that?\" you may also uncomment the extra code below.\n",
    "\n",
    "> *please be noted that the code below assuming using the same Amazone RDS. The code may fail if Amazon RDS is not available*\n",
    "\n",
    "**Getting and storing Twitter streaming data**  \n",
    "Before getting twitter streaming data, we need to install TwitterAPI library. Please be noted that our Amazon RDS server is still active by the time we wrote this note. If you find the server is not active, please do not run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install TwitterAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing installation, uncomment this code to fetch real time Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from TwitterAPI import TwitterAPI\n",
    "import MySQLdb\n",
    "import json\n",
    "\n",
    "def insert_into_db(raw):\n",
    "    db = MySQLdb.connect(host=\"mydb.c1xbtz6tteqx.us-east-1.rds.amazonaws.com\", user=\"frans\", passwd=\"smu.frans\", db=\"TwitterData\")\n",
    "    cur = db.cursor()\n",
    "    raw = raw.encode('string_escape')\n",
    "    cur.execute(\"INSERT INTO Raw(Data) VALUES(%s)\",[raw])\n",
    "    db.commit()\n",
    "    \n",
    "consumer_key = \"iMzT16JgLSyy6gaZNGjzdyoC4\"\n",
    "consumer_secret = \"bE22hKUHSEK7aiUkvemFxc6Mg5qk8pWCAT06pq7OqPSQZTgRwI\"\n",
    "access_token_key = \"161989718-UU1ZPTlcUMreZrmA6evrIvpEb7tgT9AfxVrcWoMF\"\n",
    "access_token_secret = \"IasUHu42sqcbm3sjAkvTj45rWHxXZ7jV3VdVWSSCLvvqL\"\n",
    "\n",
    "api = TwitterAPI(consumer_key, consumer_secret, access_token_key, access_token_secret)\n",
    "\n",
    "r = api.request('statuses/filter', {'track':'epl,bpl'})\n",
    "for item in r:\n",
    "    raw = json.dumps(item);\n",
    "    insert_into_db(raw)\n",
    "    print(raw)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data\n",
    "We collected the raw data from Twitter Streaming Data. Next step is to extract data. We have to extract data from raw data. There are 3 different type of extarction that we should do.  \n",
    "    1. Words Extraction\n",
    "    2. Locations Extraction\n",
    "    3. Words and Loctions Extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Words Extraction**  \n",
    "Words extraction is extracting data based on every words. We count every word occurence in each tweet. For example `Liver Pool [10]`. \"Liver Pool\" had occured for 10 times.\n",
    "\n",
    "In order to achive this approach, we need to do some coding. Below is the coding.\n",
    "\n",
    "*NOTE: Please uncomment to run the code. Running the code will take so long time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Locations Extraction**  \n",
    "Location is the same as Words Extraction. Both of extraction method also counting the number of occurence. The main difference in this method is Location Extraction use *Timezone* data.\n",
    "\n",
    "Code is provided below. Please uncomment to run the code. *Running the code will take so long time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Words and Locations Extraction**  \n",
    "This method is combine between Words Extraction and Locations Extraction methods. This method searching in which location did the word said.\n",
    "\n",
    "Code is provided below. Please uncomment to run the code. *Running the code will take so long time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import json\n",
    "import MySQLdb\n",
    "import sys\n",
    "#Connecto to Databsae\n",
    "db = MySQLdb.connect(host=\"mydb.c1xbtz6tteqx.us-east-1.rds.amazonaws.com\", user=\"frans\", passwd=\"smu.frans\", db=\"TwitterData\")\n",
    "cur = db.cursor()\n",
    "\n",
    "#Execute SQL Command to get all the data\n",
    "cur.execute(\"SELECT * FROM Raw\")\n",
    "for a in cur.fetchall():\n",
    "    try:\n",
    "        #extract the data from database\n",
    "        mydata = a[1].replace(\"\\\\\\\\\",\"\\\\\")\n",
    "        myjson = json.loads(mydata)\n",
    "        \n",
    "        #extract text and split the text by space (\" \")\n",
    "        text = myjson[\"text\"]\n",
    "        text = text.split(\" \")\n",
    "        \n",
    "        #extract location\n",
    "        location = myjson[\"user\"][\"time_zone\"]\n",
    "        \n",
    "        #store the word with the location\n",
    "        for word in text:\n",
    "            #find the count of word and location in database\n",
    "            #if not found, create a new one\n",
    "            #if found, just increment the count\n",
    "            cur2 = db.cursor()\n",
    "            cur2.execute(\"SELECT COUNT(*) FROM WordsLocation WHERE Words=%s AND Location=%s\",[word,location])\n",
    "            count = cur2.fetchone()\n",
    "            count = count[0]\n",
    "            if(count==0):\n",
    "                #insert into databaes\n",
    "                cur2.execute(\"INSERT INTO WordsLocation(Words,Location,Count) VALUES(%s,%s,%s)\",[word,location,1])\n",
    "            else:\n",
    "                cur2.execute(\"SELECT Count FROM WordsLocation WHERE Words=%s AND Location=%s\",[word,location])\n",
    "                count = cur2.fetchone()\n",
    "                count = count[0]\n",
    "                count = count + 1\n",
    "                cur2.execute(\"UPDATE WordsLocation SET Count=%s WHERE Words=%s AND Location=%s\",[count,word,location])\n",
    "            db.commit()\n",
    "    except:\n",
    "        print(\"Error: {}\".format(sys.exc_info()[0]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:red\">We did comment the process because the process can take more than 1 day. However, we provide you the intersting part! Just continue to read the docummentation below</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing plotly and dataseet\n",
    "we need to install plotly in order to make the plot works. To do that, we have to install it using this command\n",
    "```python\n",
    "sudo pip install plotly\n",
    "sudo pip install dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location Analysis\n",
    "The purpose of this analysis is to know which country has the most tweet. Run this code to know better. You need internet connection and `plotly` in order to run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~DemoAccount/57.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "import MySQLdb\n",
    "\n",
    "tls.set_credentials_file(username='DemoAccount', api_key='lr1c37zw81')\n",
    "\n",
    "# get data from database\n",
    "db = MySQLdb.connect(host=\"cloudandbigdata.cwkktstj3vyr.ap-southeast-1.rds.amazonaws.com\", user=\"frans\", passwd=\"smu.frans\", db=\"TwitterData\")\n",
    "cur = db.cursor()\n",
    "\n",
    "cur.execute(\"SELECT * FROM Location ORDER BY Count DESC LIMIT 20\")\n",
    "data = {}\n",
    "data[\"index\"] = []\n",
    "data[\"count\"] = []\n",
    "mydata = {}\n",
    "mydata[\"index\"] =[]\n",
    "mydata[\"count\"] = []\n",
    "for a in cur.fetchall():\n",
    "    try:\n",
    "        data[\"index\"].append(a[0])\n",
    "        data[\"count\"].append(a[1])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=data[\"index\"],\n",
    "        y=data[\"count\"]\n",
    "    )\n",
    "]\n",
    "py.iplot(data, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words Analysis\n",
    "We did find which word are most used by people in Twitter. Run this code to find out the result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
