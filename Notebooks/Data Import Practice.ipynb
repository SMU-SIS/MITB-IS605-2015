{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orange</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  orange  9\n",
       "0    red  4\n",
       "1  green  0\n",
       "2  green  9\n",
       "3  green  4\n",
       "4    red  8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# If your data is S3, you can download from the public url to your data. \n",
    "# You need to make sure that you set the permissions for the file in S3 to be downloadable by everyone. \n",
    "# I usually have a small copy of the data for development that I use before switching to the full dataset. \n",
    "\n",
    "#url = \"https://s3-ap-southeast-1.amazonaws.com/bigdatasg/colors_100000K.csv\"\n",
    "#url = \"https://s3-ap-southeast-1.amazonaws.com/bigdatasg/colors_10000K.csv\"\n",
    "#url = \"https://s3-ap-southeast-1.amazonaws.com/bigdatasg/colors_1000K.csv\"\n",
    "url = \"https://s3-ap-southeast-1.amazonaws.com/bigdatasg/colors_100K.csv\"\n",
    "\n",
    "\n",
    "# You can start by just loading a few rows from your small data file to ensure everything is working properly.\n",
    "# However, this approach may still try to download all of the data locally before reading in the first 20 lines. \n",
    "\n",
    "numRows = 20\n",
    "df = pd.read_csv(url, nrows=numRows)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2015-11-13 12:05:54--  https://s3-ap-southeast-1.amazonaws.com/bigdatasg/colors_100K.csv\n",
      "Resolving s3-ap-southeast-1.amazonaws.com... 54.231.241.138\n",
      "Connecting to s3-ap-southeast-1.amazonaws.com|54.231.241.138|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 799940 (781K) [application/octet-stream]\n",
      "Saving to: `colors_100K.csv.1'\n",
      "\n",
      "100%[======================================>] 799,940      132K/s   in 5.9s    \n",
      "\n",
      "2015-11-13 12:06:01 (132 KB/s) - `colors_100K.csv.1' saved [799940/799940]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "One of the easiest ways to copy data locally into your notebook while still seeing some \n",
    "feedback on the download process is to use the wget command. \n",
    "You can use linux commands from your notebook by putting a ! in front of them. \n",
    "\"\"\"\n",
    "\n",
    "!wget https://s3-ap-southeast-1.amazonaws.com/bigdatasg/colors_100K.csv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orange</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  orange  9\n",
       "0    red  4\n",
       "1  green  0\n",
       "2  green  9\n",
       "3  green  4\n",
       "4    red  8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Once you've downloading the file to your Jupyter server, you can load the data locally rather than from the url. \n",
    "\n",
    "\"\"\"\n",
    "localfile = \"colors_100K.csv\"\n",
    "numRows = 20\n",
    "df = pd.read_csv(localfile, nrows=numRows)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 100000 lines in the file.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "If you are interested in how many rows there are in your data, you could read through each row of the file\n",
    "without saving the data in to memory. Here is a quick way to do that. \n",
    "\"\"\"\n",
    "myfile = open( localfile )\n",
    "count = 0\n",
    "for line in myfile:\n",
    "   count += 1\n",
    "print(\"There were {} lines in the file.\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 10000.0 rows\n",
      "Successfully loaded 20000.0 rows\n",
      "Successfully loaded 30000.0 rows\n",
      "Successfully loaded 40000.0 rows\n",
      "Successfully loaded 50000.0 rows\n",
      "Successfully loaded 60000.0 rows\n",
      "Successfully loaded 70000.0 rows\n",
      "Successfully loaded 80000.0 rows\n",
      "Successfully loaded 90000.0 rows\n",
      "Successfully loaded 100000.0 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orange</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  orange  9\n",
       "0    red  4\n",
       "1  green  0\n",
       "2  green  9\n",
       "3  green  4\n",
       "4    red  8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sometimes your system will not have sufficient memory to read all of your data in to memory. \n",
    "When you try to read too much data in to memory, you will crash your kernel. \n",
    "This happens a lot in micro instanes since they only have 1GB of memory that Linux, Docker, and Jupyter must share. \n",
    "If you are ever interested in figuring out where your instances is breaking, you can incrementally try to load the file. \n",
    "\"\"\"\n",
    "\n",
    "step_size = count / 10.0\n",
    "\n",
    "for x in range(1,11):\n",
    "    numRows = step_size * x\n",
    "    df=pd.read_csv(localfile, nrows=numRows)\n",
    "    print(\"Successfully loaded {} rows\".format(numRows))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
